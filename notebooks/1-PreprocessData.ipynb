{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Constants\n",
    "RAW_DATA_DIR = \"../data/raw/\"\n",
    "PROCESSED_DATA_DIR = \"../data/processed/\"\n",
    "COUNTRY = \"MYS\"  # ISO-3 Code for Malaysia\n",
    "\n",
    "\n",
    "def extract_info_from_filename(filename: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Extracts origin year and age group from the filename.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The name of the file.\n",
    "\n",
    "    Returns:\n",
    "        tuple[str, str]: A tuple containing the year and age group.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example filename: \"2020_0-4.csv\"\n",
    "    # This regex captures the year and age group.\n",
    "    pattern = r\"(\\d{4})_(.+)\\.csv\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        year: str = match.group(1)\n",
    "        age_group: str = match.group(2)\n",
    "        return year, age_group\n",
    "    raise ValueError(f\"Filename {filename} does not match expected pattern.\")\n",
    "\n",
    "\n",
    "def process_csv_file(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a CSV file and returns the data.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the processed data.\n",
    "    \"\"\"\n",
    "\n",
    "    year, age_group = extract_info_from_filename(os.path.basename(file_path))\n",
    "\n",
    "    # Read the file - skip the first 8 rows which contain metadata/headers\n",
    "    df = pd.read_csv(file_path, skiprows=7, low_memory=False)\n",
    "\n",
    "    malaysia_col_idx: int = -1\n",
    "    for col_idx, col_name in enumerate(df.columns):\n",
    "        if col_name == COUNTRY:\n",
    "            malaysia_col_idx = col_idx\n",
    "            break\n",
    "\n",
    "    if malaysia_col_idx == -1:\n",
    "        raise ValueError(f\"Country '{COUNTRY}' not found in columns of {file_path}\")\n",
    "\n",
    "    result_data: list[dict[str, str | float]] = []\n",
    "\n",
    "    disease_l1: str = \"\"\n",
    "    disease_l2: str = \"\"\n",
    "    disease_l3: str = \"\"\n",
    "    disease_l4: str = \"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        sex: str = row.iloc[0]\n",
    "\n",
    "        # Extract disease levels\n",
    "        if pd.notna(row.iloc[3]) and len(str(row.iloc[3])) > 2:\n",
    "            disease_l1 = row.iloc[3]\n",
    "            disease_l2 = \"\"\n",
    "            disease_l3 = \"\"\n",
    "            disease_l4 = \"\"\n",
    "        elif pd.notna(row.iloc[4]) and len(str(row.iloc[4])) > 2:\n",
    "            disease_l2 = row.iloc[4]\n",
    "            disease_l3 = \"\"\n",
    "            disease_l4 = \"\"\n",
    "        elif pd.notna(row.iloc[5]) and len(str(row.iloc[5])) > 2:\n",
    "            disease_l3 = row.iloc[5]\n",
    "            disease_l4 = \"\"\n",
    "        elif pd.notna(row.iloc[6]) and len(str(row.iloc[6])) > 2:\n",
    "            disease_l4 = row.iloc[6]\n",
    "\n",
    "        # Skip population rows\n",
    "        if str(disease_l1).startswith(\" Population\") or str(disease_l1) == \"\":\n",
    "            disease_l1 = \"\"\n",
    "            continue\n",
    "\n",
    "        # Get mortality count for Malaysia\n",
    "        try:\n",
    "            mortality_value: str = (\n",
    "                row.iloc[malaysia_col_idx]\n",
    "                if pd.notna(row.iloc[malaysia_col_idx])\n",
    "                else \"0\"\n",
    "            )\n",
    "            # Dataset unit is per 1000 population\n",
    "            mortality_count = float(mortality_value) * 1000\n",
    "            mortality_count = int(mortality_count)\n",
    "        except (ValueError, TypeError) as e:\n",
    "            print(\n",
    "                f\"Error processing mortality value in file {file_path}, row {index}: {e}\"\n",
    "            )\n",
    "            mortality_count = 0\n",
    "\n",
    "        result_data.append(\n",
    "            {\n",
    "                \"Year\": year,\n",
    "                \"Age Group\": age_group,\n",
    "                \"Disease_L1\": disease_l1,\n",
    "                \"Disease_L2\": disease_l2,\n",
    "                \"Disease_L3\": disease_l3,\n",
    "                \"Disease_L4\": disease_l4,\n",
    "                \"Sex\": sex,\n",
    "                \"Mortality Count\": mortality_count,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return pd.DataFrame(result_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459e030",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(os.path.join(RAW_DATA_DIR, \"*.csv\"))\n",
    "all_data: list[pd.DataFrame] = []\n",
    "\n",
    "for file in all_files:\n",
    "    try:\n",
    "        df = process_csv_file(file)\n",
    "        all_data.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "if all_data == []:\n",
    "    raise ValueError(\"No data was processed. Check the input files.\")\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "final_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Save the processed data to a CSV file\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)\n",
    "output_file: str = os.path.join(PROCESSED_DATA_DIR, \"malaysia_mortality_data_eda.csv\")\n",
    "final_df.to_csv(output_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
